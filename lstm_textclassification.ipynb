{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=16\n",
    "EPOCHES = 5\n",
    "L_R = 0.01\n",
    "HIDDEN_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "\n",
    "    root='./mnist/',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_data.size())\n",
    "test_data = torchvision.datasets.MNIST(root='./mnist/',train=False)\n",
    "\n",
    "train_loader = Data.DataLoader(dataset=train_data,batch_size=BATCH_SIZE,shuffle=True)\n",
    "# test_loader = Data.DataLoader(dataset=test_data,batch_size=BATCH_SIZE,shuffle=True)#wrong\n",
    "test_x = torch.unsqueeze(test_data.test_data,dim=1).type(torch.FloatTensor)[:3000]/255    #3000 samples\n",
    "test_y = test_data.test_labels[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 28, 28])\n",
      "\n",
      " 5\n",
      " 1\n",
      " 2\n",
      " 0\n",
      " 4\n",
      " 0\n",
      " 3\n",
      " 4\n",
      " 4\n",
      " 7\n",
      " 4\n",
      " 8\n",
      " 1\n",
      " 1\n",
      " 3\n",
      " 0\n",
      "[torch.LongTensor of size 16]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,(b_x,b_y) in enumerate(train_loader):\n",
    "    print(b_x.squeeze(1).size())\n",
    "    print(b_y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self,hidden_size,output_size):\n",
    "        super(net,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.rnn = nn.LSTM(28,hidden_size)\n",
    "        self.out = nn.Linear(hidden_size,output_size)\n",
    "    def forward(self,x_inputs):\n",
    "        \n",
    "        rnn_out,_ = self.rnn(x_inputs)\n",
    "        rnn_out = rnn_out[-1].squeeze(0) #BATCH*HIDDEN_SIZE\n",
    "        out = F.relu(self.out(rnn_out))\n",
    "        return F.log_softmax(out)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = net(HIDDEN_SIZE,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=L_R)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0,step:0,loss:2.3030\n",
      "epoch:0,step:500,loss:1.6864\n",
      "epoch:0,step:1000,loss:0.4679\n",
      "epoch:0,step:1500,loss:1.1451\n",
      "epoch:0,step:2000,loss:0.4933\n",
      "epoch:0,step:2500,loss:0.9470\n",
      "epoch:0,step:3000,loss:1.0767\n",
      "epoch:0,step:3500,loss:1.2987\n",
      "epoch:0,total_loss:3938.0393\n",
      "epoch:1,step:0,loss:1.0885\n",
      "epoch:1,step:500,loss:0.7696\n",
      "epoch:1,step:1000,loss:0.6904\n",
      "epoch:1,step:1500,loss:0.7353\n",
      "epoch:1,step:2000,loss:0.5828\n",
      "epoch:1,step:2500,loss:0.4408\n",
      "epoch:1,step:3000,loss:0.8845\n",
      "epoch:1,step:3500,loss:1.0252\n",
      "epoch:1,total_loss:3230.8967\n",
      "epoch:2,step:0,loss:0.7710\n",
      "epoch:2,step:500,loss:0.4623\n",
      "epoch:2,step:1000,loss:0.3811\n",
      "epoch:2,step:1500,loss:0.5873\n",
      "epoch:2,step:2000,loss:0.4643\n",
      "epoch:2,step:2500,loss:0.4542\n",
      "epoch:2,step:3000,loss:0.3937\n",
      "epoch:2,step:3500,loss:0.9160\n",
      "epoch:2,total_loss:3151.6379\n",
      "epoch:3,step:0,loss:0.8921\n",
      "epoch:3,step:500,loss:0.5837\n",
      "epoch:3,step:1000,loss:0.5658\n",
      "epoch:3,step:1500,loss:0.4410\n",
      "epoch:3,step:2000,loss:1.2964\n",
      "epoch:3,step:2500,loss:0.7247\n",
      "epoch:3,step:3000,loss:1.1018\n",
      "epoch:3,step:3500,loss:0.6055\n",
      "epoch:3,total_loss:3193.4389\n",
      "epoch:4,step:0,loss:0.2945\n",
      "epoch:4,step:500,loss:1.1958\n",
      "epoch:4,step:1000,loss:1.1763\n",
      "epoch:4,step:1500,loss:0.6799\n",
      "epoch:4,step:2000,loss:0.3947\n",
      "epoch:4,step:2500,loss:1.2273\n",
      "epoch:4,step:3000,loss:0.8510\n",
      "epoch:4,step:3500,loss:0.7900\n",
      "epoch:4,total_loss:3624.0889\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHES):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i,(b_x,b_y) in enumerate(train_loader):\n",
    "        loss = 0\n",
    "        model.zero_grad()\n",
    "        b_x = b_x.squeeze(1)\n",
    "        b_x = Variable(b_x).transpose(0,1)\n",
    "        b_y = Variable(b_y)\n",
    "        output = model(b_x)\n",
    "        loss = criterion(output,b_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.data[0]\n",
    "        if i % 500 == 0:\n",
    "            print('epoch:%d,step:%d,loss:%.4f'%(epoch,i,loss.data[-1]))\n",
    "#         print('step:%d...loss:%.4f...'%(i,loss.data[0]))\n",
    "    print('epoch:%d,total_loss:%.4f'%(epoch,total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total = 0\n",
    "correct = 0\n",
    "# output = model(Variable(test_x[0:10]))\n",
    "# print(output)\n",
    "import numpy as np\n",
    "def random_batch(x,y,batch_size):\n",
    "    len_data = len(x)\n",
    "#     data ,y = np.array(x),np.array(y)\n",
    "    batch_num = int(np.ceil(len_data/batch_size))\n",
    "    shuffle_idx = np.random.permutation(np.arange(len_data))\n",
    "    shuffle_data = x[shuffle_idx]\n",
    "    shuffle_label = y[shuffle_idx]\n",
    "    print(shuffle_data.size())\n",
    "    for i in range(batch_num):\n",
    "        start_idx = batch_size*i\n",
    "        end_idx = min(batch_size*(i+1),len_data)\n",
    "        yield shuffle_data[start_idx,end_idx],y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3000, 1, 28, 28])\n",
      "torch.Size([3000])\n"
     ]
    }
   ],
   "source": [
    "print(test_x.size())\n",
    "print(test_y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 28, 28])\n",
      "\n",
      "\n",
      "Columns 0 to 12 \n",
      "    3     0     7     3     0     0     7     7     2     0     5     5     5\n",
      "\n",
      "Columns 13 to 15 \n",
      "    0     7     2\n",
      "[torch.LongTensor of size 1x16]\n",
      "\n",
      "\n",
      "\n",
      "Columns 0 to 12 \n",
      "    7     2     1     0     4     1     4     9     5     9     0     6     9\n",
      "\n",
      "Columns 13 to 15 \n",
      "    0     1     5\n",
      "[torch.LongTensor of size 1x16]\n",
      "\n",
      "16\n",
      "\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "[torch.ByteTensor of size 16x1]\n",
      "\n",
      "1\n",
      "test accury is:0.0625\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "x_val = Variable(test_x.squeeze(1)[:16])\n",
    "print(x_val.size())\n",
    "ouput = model(x_val.transpose(0,1))\n",
    "# print(output)\n",
    "_,predict = torch.max(output.data,1)\n",
    "print(predict.transpose(0,1))\n",
    "print(test_y[:16].view(1,-1))\n",
    "#     print(predict)\n",
    "#     break\n",
    "total += 16\n",
    "print(total)\n",
    "print(predict== test_y[:16]).contiguous()\n",
    "print(torch.sum(predict== test_y[:16]))\n",
    "correct += torch.sum(predict== test_y[:16])\n",
    "print('test accury is:%.4f'%(correct*1.0/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "indexing a tensor with an object of type numpy.ndarray. The only supported types are integers, slices, numpy scalars and torch.LongTensor or torch.ByteTensor as the only argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b3c69a96bb3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandom_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mb_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     print(b_x.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9dca21682540>\u001b[0m in \u001b[0;36mrandom_batch\u001b[0;34m(x, y, batch_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbatch_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_data\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mshuffle_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mshuffle_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshuffle_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mshuffle_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshuffle_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffle_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: indexing a tensor with an object of type numpy.ndarray. The only supported types are integers, slices, numpy scalars and torch.LongTensor or torch.ByteTensor as the only argument."
     ]
    }
   ],
   "source": [
    "for (b_x,b_y) in random_batch(test_x,test_y,BATCH_SIZE):\n",
    "    b_x = Variable(b_x)\n",
    "#     print(b_x.size())\n",
    "\n",
    "    output = model(b_x)\n",
    "    _,predict = torch.max(output,1)\n",
    "#     print(predict)\n",
    "#     break\n",
    "    total += len(b_x)\n",
    "    correct += (predict == b_y).float().sum()\n",
    "print('test accury is:%.4f'%(correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
